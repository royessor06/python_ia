from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
import torch
import warnings
warnings.filterwarnings('ignore')

class FrenchChatbot:
    def __init__(self, model_name="microsoft/DialoGPT-small"):
        """
        Initialise le chatbot avec un mod√®le adapt√© au dialogue
        DialoGPT est mieux pour la conversation que GPT-Neo
        """
        print("‚ö° Chargement du mod√®le...")
        
        # Charger mod√®le et tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(model_name)
        
        # Cr√©er un pipeline pour simplifier
        self.generator = pipeline(
            'text-generation',
            model=self.model,
            tokenizer=self.tokenizer,
            device=0 if torch.cuda.is_available() else -1
        )
        
        # Configuration du tokenizer
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        # Historique de conversation
        self.history = []
        self.max_history = 4  # Garde les 4 derniers √©changes
        
        print("‚úÖ Pr√™t ! Tape 'aide' pour les commandes\n")
    
    def format_prompt(self, user_input):
        """Formate le prompt avec l'historique"""
        # Ajouter la nouvelle entr√©e
        self.history.append(f"Utilisateur: {user_input}")
        
        # Garder seulement les derniers √©changes
        if len(self.history) > self.max_history * 2:
            self.history = self.history[-(self.max_history * 2):]
        
        # Cr√©er le prompt
        prompt = "Tu es un assistant fran√ßais intelligent et serviable.\n"
        prompt += "R√©ponds de mani√®re naturelle et conversationnelle en fran√ßais.\n\n"
        
        # Ajouter l'historique
        for i in range(0, len(self.history) - 1, 2):
            if i + 1 < len(self.history):
                prompt += f"{self.history[i]}\n{self.history[i+1]}\n"
        
        prompt += f"{self.history[-1]}\nAssistant:"
        return prompt
    
    def clean_response(self, response, user_input):
        """Nettoie la r√©ponse g√©n√©r√©e"""
        # Supprimer la r√©p√©tition de la question
        if response.startswith(user_input):
            response = response[len(user_input):]
        
        # Supprimer les pr√©fixes ind√©sirables
        prefixes = ["Assistant:", "R√©ponse:", "Bot:"]
        for prefix in prefixes:
            if response.startswith(prefix):
                response = response[len(prefix):]
        
        # Nettoyer les espaces
        response = response.strip()
        
        # Supprimer tout apr√®s un saut de ligne
        if '\n' in response:
            response = response.split('\n')[0]
        
        return response
    
    def generate_response(self, user_input):
        """G√©n√®re une r√©ponse"""
        prompt = self.format_prompt(user_input)
        
        # G√©n√©rer la r√©ponse
        response = self.generator(
            prompt,
            max_length=200,
            min_length=20,
            temperature=0.85,  # Un peu cr√©atif mais coh√©rent
            top_p=0.92,
            top_k=50,
            do_sample=True,
            repetition_penalty=1.2,  # √âvite la r√©p√©tition
            num_return_sequences=1,
            pad_token_id=self.tokenizer.pad_token_id,
            eos_token_id=self.tokenizer.eos_token_id,
            truncation=True
        )[0]['generated_text']
        
        # Extraire seulement la nouvelle r√©ponse
        response = response[len(prompt):]
        response = self.clean_response(response, user_input)
        
        # Ajouter √† l'historique
        self.history.append(f"Assistant: {response}")
        
        return response
    
    def show_help(self):
        """Affiche l'aide"""
        print("\n" + "="*50)
        print("ü§ñ COMMANDES DISPONIBLES :")
        print("="*50)
        print("  'aide'      - Affiche ce message")
        print("  'clear'     - Efface l'historique")
        print("  'history'   - Affiche l'historique")
        print("  'quit'      - Quitte le programme")
        print("  'au revoir' - Quitte le programme")
        print("  'mode [x]'  - Change le mode (1=simple, 2=cr√©atif)")
        print("="*50 + "\n")
    
    def run(self):
        """Lance la boucle de conversation"""
        print("\n" + "‚ú®"*25)
        print("    CHATBOT FRAN√áAIS AVANC√â")
        print("‚ú®"*25 + "\n")
        
        modes = {
            '1': {'temp': 0.7, 'top_p': 0.9},
            '2': {'temp': 0.9, 'top_p': 0.95}
        }
        current_mode = '1'
        
        while True:
            try:
                # Obtenir l'entr√©e utilisateur
                user_input = input("\nüë§ Vous: ").strip()
                
                if not user_input:
                    continue
                
                # Commandes sp√©ciales
                if user_input.lower() == 'quit' or user_input.lower() == 'au revoir':
                    print("\nü§ñ Au revoir ! √Ä bient√¥t ! üëã")
                    break
                
                elif user_input.lower() == 'aide':
                    self.show_help()
                    continue
                
                elif user_input.lower() == 'clear':
                    self.history = []
                    print("ü§ñ Historique effac√© !")
                    continue
                
                elif user_input.lower() == 'history':
                    print("\nüìú Historique:")
                    for i, msg in enumerate(self.history):
                        print(f"  {i+1}. {msg}")
                    continue
                
                elif user_input.lower().startswith('mode '):
                    mode = user_input.split()[-1]
                    if mode in modes:
                        current_mode = mode
                        self.generator.task_kwargs['temperature'] = modes[mode]['temp']
                        print(f"ü§ñ Mode chang√© √† {'Simple' if mode == '1' else 'Cr√©atif'}")
                    else:
                        print("ü§ñ Mode invalide. Utilise 1 ou 2.")
                    continue
                
                # G√©n√©rer et afficher la r√©ponse
                print("ü§ñ Assistant: ", end='', flush=True)
                
                response = self.generate_response(user_input)
                
                # Afficher progressivement (effet de saisie)
                for char in response:
                    print(char, end='', flush=True)
                    import time
                    time.sleep(0.01)
                print()
                
                # Limiter la taille de l'historique
                if len(self.history) > 8:
                    self.history = self.history[-8:]
                    
            except KeyboardInterrupt:
                print("\n\nü§ñ Interruption d√©tect√©e. Au revoir !")
                break
            except Exception as e:
                print(f"\n‚ö†Ô∏è  Erreur: {e}")
                print("R√©essayez...")

# Configuration avanc√©e
if __name__ == "__main__":
    # Liste de mod√®les possibles (choisir un)
    MODELS = {
        "1": "microsoft/DialoGPT-small",      # Bon pour dialogue
        "2": "gpt2",                          # GPT-2 standard
        "3": "asi/gpt-fr-cased-small",        # Fran√ßais
        "4": "distilgpt2"                     # L√©ger et rapide
    }
    
    print("üß† CHOIX DU MOD√àLE :")
    for key, value in MODELS.items():
        print(f"  {key}. {value}")
    
    choice = input("\nChoisis un mod√®le (1-4) [1 par d√©faut]: ").strip() or "1"
    model_name = MODELS.get(choice, MODELS["1"])
    
    # Cr√©er et lancer le chatbot
    bot = FrenchChatbot(model_name)
    bot.run()